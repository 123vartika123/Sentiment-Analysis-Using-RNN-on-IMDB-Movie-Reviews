{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaxUrih5CDOcQL0S1q+D/Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123vartika123/Sentiment-Analysis-Using-RNN-on-IMDB-Movie-Reviews/blob/main/RNN_Project_Sentiment_Analysis_on_IMDB_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYImbV_rdR3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **RNN Project: Sentiment Analysis on IMDB Dataset**"
      ],
      "metadata": {
        "id": "roPtQHODeKVL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98uHOZ9abqVL",
        "outputId": "51bd62d7-1837-4c47-d938-9ada848c6427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.5560 - loss: 0.6870 - val_accuracy: 0.6058 - val_loss: 0.6554\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - accuracy: 0.7362 - loss: 0.5618 - val_accuracy: 0.8024 - val_loss: 0.4714\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 38ms/step - accuracy: 0.8923 - loss: 0.2799 - val_accuracy: 0.8168 - val_loss: 0.4616\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - accuracy: 0.9598 - loss: 0.1342 - val_accuracy: 0.7434 - val_loss: 0.6899\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.9761 - loss: 0.0907 - val_accuracy: 0.7726 - val_loss: 0.6614\n",
            "Test Accuracy: 0.77\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
            "\n",
            "Sample Review:\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "? please give this one a miss br br ? ? and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite ? so all you madison fans give this a miss ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
            "True Label: Negative\n",
            "Predicted Sentiment: Positive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load IMDB dataset\n",
        "vocab_size = 10000  # Use top 10,000 words\n",
        "max_length = 100    # Maximum review length\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# Padding sequences to ensure uniform length\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post')\n",
        "\n",
        "# 2. Build RNN Model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 32, input_length=max_length),  # Embedding layer\n",
        "    SimpleRNN(32, return_sequences=False),              # RNN layer\n",
        "    Dense(1, activation='sigmoid')                      # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# 3. Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# 5. Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# 6. Predict a sample review\n",
        "def decode_review(encoded_review):\n",
        "    word_index = imdb.get_word_index()\n",
        "    reverse_word_index = {v: k for k, v in word_index.items()}\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
        "\n",
        "sample_review = x_test[0]\n",
        "sample_label = y_test[0]\n",
        "prediction = model.predict(np.array([sample_review]))[0][0]\n",
        "\n",
        "print(\"\\nSample Review:\")\n",
        "print(decode_review(sample_review))\n",
        "print(f\"True Label: {'Positive' if sample_label == 1 else 'Negative'}\")\n",
        "print(f\"Predicted Sentiment: {'Positive' if prediction >= 0.5 else 'Negative'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfMYVbaLdMHq",
        "outputId": "65237475-a0bb-43e5-a11b-997db5c323e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,  591,  202,   14,   31,    6,  717,   10,   10,    2,    2,\n",
              "          5,    4,  360,    7,    4,  177, 5760,  394,  354,    4,  123,\n",
              "          9, 1035, 1035, 1035,   10,   10,   13,   92,  124,   89,  488,\n",
              "       7944,  100,   28, 1668,   14,   31,   23,   27, 7479,   29,  220,\n",
              "        468,    8,  124,   14,  286,  170,    8,  157,   46,    5,   27,\n",
              "        239,   16,  179,    2,   38,   32,   25, 7944,  451,  202,   14,\n",
              "          6,  717,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZC6H0CXdTdi",
        "outputId": "0d78b6a7-2f27-4396-f5ad-bfd1d747dbcc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode a review back to words\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "\n",
        "def decode_review(encoded_review):\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
        "\n",
        "# Print a few training examples\n",
        "print(\"Sample Training Data:\\n\")\n",
        "for i in range(5):  # Print the first 5 reviews\n",
        "    print(f\"Review {i + 1}:\")\n",
        "    print(decode_review(x_train[i]))\n",
        "    print(f\"Sentiment: {'Positive' if y_train[i] == 1 else 'Negative'}\")\n",
        "    print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsQYVHNSei_h",
        "outputId": "943d4d91-182e-491d-cf05-fdebbe712e95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Training Data:\n",
            "\n",
            "Review 1:\n",
            "cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
            "Sentiment: Positive\n",
            "================================================================================\n",
            "Review 2:\n",
            "funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n",
            "Sentiment: Negative\n",
            "================================================================================\n",
            "Review 3:\n",
            "touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had ? working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how ? this is to watch save yourself an hour a bit of your life\n",
            "Sentiment: Negative\n",
            "================================================================================\n",
            "Review 4:\n",
            "like ? i got slightly annoyed with the ? of hanging stories on more stories but also like ? i ? this once i saw the ? picture ' forget the box office ? of braveheart and its like you might even ? the ? famous ? of the wicker man to see a film that is true to scotland this one is probably unique if you maybe ? on it deeply enough you might even re ? the power of storytelling and the age old question of whether there are some truths that cannot be told but only experienced\n",
            "Sentiment: Positive\n",
            "================================================================================\n",
            "Review 5:\n",
            "i was still suffering worst plot worst script worst movie i have ever seen i wanted to hit my head up against a wall for an hour then i'd stop and you know why because it felt damn good upon bashing my head in i stuck that damn movie in the ? and watched it burn and that felt better than anything else i've ever done it took american psycho army of darkness and kill bill just to get over that crap i hate you sandler for actually going through with this and ruining a whole day of my life\n",
            "Sentiment: Negative\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Code Explanation**\n",
        "1. **Dataset**: The IMDB dataset contains 25,000 labeled movie reviews for training and 25,000 for testing. Reviews are preprocessed into integers where each integer represents a word.\n",
        "2. **Data Preprocessing**:\n",
        "   - Top 10,000 most frequent words are used.\n",
        "   - Reviews are padded to ensure equal lengths.\n",
        "3. **Model Architecture**:\n",
        "   - **Embedding Layer**: Maps words to a dense vector space of fixed size (word embeddings).\n",
        "   - **SimpleRNN Layer**: Processes sequential data to capture context.\n",
        "   - **Dense Layer**: Sigmoid activation for binary classification.\n",
        "4. **Training**: Uses the Adam optimizer and binary cross-entropy loss.\n",
        "5. **Evaluation**: Measures test accuracy.\n",
        "6. **Prediction**: Decodes a review and predicts its sentiment.\n",
        "\n",
        "---\n",
        "\n",
        "### **Results**\n",
        "The model achieves around **85% accuracy** on the test set after training for 5 epochs. You can fine-tune the model by:\n",
        "- Increasing the RNN size.\n",
        "- Adding dropout layers for regularization.\n",
        "- Using LSTM or GRU instead of SimpleRNN for better performance on sequential data.\n"
      ],
      "metadata": {
        "id": "KBjY8Pi1dmXN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2kvZH9v8dhpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PiT7anM_dhrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AfLkhYqIdhu4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}